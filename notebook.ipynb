{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "calendar=pd.read_csv('data/calendar.csv')\n",
    "listings=pd.read_csv('data/listings.csv')\n",
    "reviews=pd.read_csv('data/reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business understanding of the project\n",
    "\n",
    "Airbnb is an online marketplace to connect hosts and guests for lodging or tourism experiences. Airbnb serves as an alternative to hotels. Advantanges and disadvantages of Airbnb compared to hotels.\n",
    "\n",
    "Advantages: \n",
    "1. Could be less expensive than hotels\n",
    "2. Adding benefits of kitchens and hostpitabilites.\n",
    "3. Could be great for family travels.\n",
    "\n",
    "Disadvantages:\n",
    "1. For business travel, hotel might just be easier.\n",
    "2. Hosts can be more quirky or friendly than hotel staff.\n",
    "3. Rooms could be less clean than hotels. \n",
    "4. Sharing rooms with other guest could be unpredictable.\n",
    "5. Prices is determined by host, which is unot necessarily reasonble.\n",
    "6. Overall, the experience is less standardized and might not be suitable for people who are looking for predictability.\n",
    "\n",
    "On the other side of the market, hosts could make extra money by subletting a guest room in holidays or entire home while you're away. commerical rentals are possible but might not be advised in terms of amount of money you can make and regulations on short-term rentals, it also might not be the purpose for using this platform. Some disadvantages for hosts using Airbnb: Some buildings not allow for short-term sublet. safety issues about guests. could feel that guest mess up with your home. perhaps relatively longer terms, less guests, exchanging information before guests coming to know about them.\n",
    "\n",
    "Is superhost a good thing or not? perhaps not sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some questions** I try to answer with this dataset\n",
    "1. Can you describe the vibe of each Seattle neighborhood using listing descriptions?\n",
    "2. What are the busiest times of the year to visit Seattle? By how much do prices spike?\n",
    "3. What do people generally say about these listings? perhaps in different areas?\n",
    "4. Does price related to any of the variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are downloaded from https://www.kaggle.com/airbnb/seattle\n",
    "Data are posted by Airbnb to Kaggle, but original data are collected by Airbnb Inside (scraped from Airbnb public available data), which is an personal funded site not associated with Airbnb. More about Airbnb Inside and this original data can be found here http://insideairbnb.com/about.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes one year's data- price and availability- scraped from the website. Could see time trends of price over the year. availability throughout the year. listings include desciption about the place, host information, neighborhood information, room details, prices, availaiblities, reivew scores, and some other info. reviews include guest comments for the listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.max_columns = 10\n",
    "#listings.info()\n",
    "# 3818 listings, 2751 hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring dataset with `df.head()`, `df.info()`, `df.describe()`,\n",
    "\n",
    "know that calendar includes listing id and the price and availability for a day; listings includes full descriptions and average review score; reviews includes unique id for each reviewer and detailed comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up price column in listings. remove \"$\" and \",\" and convert to numerical values\n",
    "listings['price']=listings['price'].map(lambda x: x.strip('$').replace(',', ''))\n",
    "listings['price']=listings['price'].map(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similary for caldenar, clean up price column (only where it's not nan) and change data type for date\n",
    "calendar.loc[pd.notnull(calendar['price']),'price']=calendar.loc[pd.notnull(calendar['price']),'price'].map(lambda x: x.strip('$').replace(',', ''))\n",
    "calendar['price']=calendar['price'].map(float)\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count for one listing description\n",
    "# tried to group description by review scores to see if any difference between of description by review scores, \n",
    "# but majority of reviews are very good- scores 9 or 10\n",
    "tokens = nltk.word_tokenize(listings['space'][0])\n",
    "sw = set(stopwords.words('english'))\n",
    "tokens = [x for x in tokens if x not in sw]\n",
    "punc=['.', ',', '(', ')']\n",
    "tokens = [x for x in tokens if x not in punc]\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#lemmatizer = WordNetLemmatizer() \n",
    "#tokens = [lemmatizer.lemmatize(x) for x in tokens]\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(tokens).most_common(10)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what did reviewers say about the listings. word count of reviews by neighborhood\n",
    "reviews=reviews.merge(listings[['id', 'neighbourhood_group_cleansed', 'host_name']], how='inner', left_on='listing_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_all = []\n",
    "stopwords_to_remove = set(stopwords.words('english'))\n",
    "others_to_remove=['.', ',', '(', ')', '&', ':', '!', '-', '*', 'The', 'apartment', \"'s\", 'Seattle', 'This', \n",
    "                  'I', 'We', 'us', 'It', 'stay', 'place', 'host', \"n't\", 'would', 'room', 'home']\n",
    "for comment in reviews.loc[(reviews['neighbourhood_group_cleansed']=='Central Area') & pd.notnull(reviews['comments']), 'comments'].tolist():\n",
    "    tokens = nltk.word_tokenize(comment)\n",
    "    tokens = [x for x in tokens if x not in stopwords_to_remove]\n",
    "    tokens = [x for x in tokens if x not in others_to_remove]\n",
    "    tokens_all = tokens_all + tokens\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(tokens_all).most_common(30)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to download nltk if not used before otherwise will pop up TK errors\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter matrix of numerical variables to explore their relationships to price\n",
    "# could use pandas plotting.scatter_matrix or seaborn pairplot\n",
    "#pd.plotting.scatter_matrix(listings[['price', 'review_scores_value', 'square_feet', 'bedrooms', 'number_of_reviews']], \n",
    "#                           figsize = (9, 9))\n",
    "\n",
    "# for seaborn pairplot, histogram diagnols don't accept nans so has to be kde diagnols\n",
    "#sns.pairplot(listings, vars=['price', 'review_scores_value', 'square_feet', 'bedrooms', 'number_of_reviews'], diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of listing prices\n",
    "listings['price'].plot.hist(bins=30)\n",
    "#plt.ylabel('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe listing prices\n",
    "# listings['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize price by bedrooms\n",
    "listings.loc[listings['bedrooms']==0, 'bedrooms']=0.5\n",
    "listings['price_per_bed']=listings['price']/(listings['bedrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average price by location. groupby and visuals. visual could be matplotlib errorbar or seaborn pointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between neighborhood and neighbourhood_group_cleansed? choose one of the fields as location group\n",
    "listings['neighbourhood'].unique()\n",
    "#listings.loc[listings['neighbourhood_group_cleansed']=='Cascade', 'neighbourhood'].unique()\n",
    "#listings.loc[listings['neighbourhood']=='Eastlake', 'neighbourhood_group_cleansed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of lists by location\n",
    "neighborcts=listings.groupby(['neighbourhood_group_cleansed'], as_index=False)['id'].count()\n",
    "neighborcts.sort_values(by='id', ascending=False, inplace=True)\n",
    "neighborcts.plot.bar(x='neighbourhood_group_cleansed', y='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_by_area=listings.groupby(['neighbourhood_group_cleansed'],as_index=False)['price'].agg([np.mean, 'sem', 'count', 'max', 'min', 'median']).reset_index()\n",
    "price_by_area.sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "plt.errorbar(x=price_by_area.index.tolist(), y=price_by_area['mean'], yerr=price_by_area['sem']*2,fmt='o')\n",
    "plt.xticks(price_by_area.index.tolist())\n",
    "plt.gca().set_xticklabels(price_by_area['neighbourhood_group_cleansed'],rotation=90);\n",
    "#plt.show()\n",
    "# sns.pointplot(x='neighbourhood_group_cleansed',y='price', data=listings, join=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review by location\n",
    "#review_by_area=listings.groupby(['neighbourhood_group_cleansed'],as_index=False)['review_scores_value'].agg([np.mean, 'sem', 'count', 'max', 'min', 'median']).reset_index()\n",
    "#review_by_area.sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent super host by location\n",
    "#listings['host_is_superhost']=listings['host_is_superhost'].apply(lambda x: 1 if x=='t' else 0)\n",
    "#pct_super_by_area=listings.groupby(['neighbourhood_group_cleansed'],as_index=False)['host_is_superhost'].mean()\n",
    "#pct_super_by_area.sort_values(by='host_is_superhost', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## average price by review scores\n",
    "#price_by_review=listings.groupby(['review_scores_value'],as_index=False)['price'].agg([np.mean, 'sem', 'count', 'max', 'min', 'median']).reset_index()\n",
    "#price_by_review.sort_values(by='mean', ascending=False)\n",
    "##plt.figure(figsize=(6.4,4.8))\n",
    "#plt.errorbar(x=price_by_review.index.tolist(), y=price_by_review['mean'], yerr=price_by_review['sem']*2,fmt='o')\n",
    "#plt.xticks(price_by_review.index.tolist())\n",
    "#plt.gca().set_xticklabels(price_by_review['review_scores_value'],rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price by property type\n",
    "#price_by_bedType=listings.groupby(['property_type'],as_index=False)['price'].agg([np.mean, 'sem', 'count', 'max', 'min', 'median']).reset_index()\n",
    "#price_by_bedType.sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time trends for average price for each neighborhood. merge with listings to get neighborhood information first\n",
    "#calendar['week']=calendar['date'].dt.week\n",
    "calendar = pd.merge(calendar, listings[['id', 'neighbourhood_group_cleansed']], left_on='listing_id', right_on='id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_avg_by_date=calendar.groupby(['neighbourhood_group_cleansed', 'date'], as_index=False)['price'].mean()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=neighbor_avg_by_date, x='date', y='price', hue='neighbourhood_group_cleansed')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only parameters that are possibly related to price\n",
    "# listings.info()\n",
    "#sns.set_context('talk') #rc={'axes.labelsize': 16})\n",
    "listings_less = listings[['transit', 'neighbourhood_group_cleansed',\n",
    "                         'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', \n",
    "                         'amenities', 'square_feet', 'number_of_reviews', 'price']].copy()\n",
    "#sns.pairplot(listings_less, diag_kind = 'kde')\n",
    "pd.plotting.scatter_matrix(listings_less, figsize=(10,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values\n",
    "# fill property_type as mode\n",
    "# fill bathrooms, bedrooms, beds as median\n",
    "# fill square_feet as 0 and add another column is_nan_square_feet as 1 to indicate nan values in square_feet\n",
    "# fill blanks for missing transit\n",
    "listings_less['property_type'] = listings_less['property_type'].fillna(listings_less['property_type'].mode())\n",
    "for col in ['bathrooms', 'bedrooms', 'beds']:\n",
    "    listings_less[col] = listings_less[col].fillna(listings_less[col].median())\n",
    "listings_less.loc[pd.isnull(listings_less['square_feet']), 'square_feet'] = 0\n",
    "listings_less.loc[listings_less['square_feet']<10, 'square_feet'] = 0 # change small values to zero\n",
    "listings_less['is_nan_square_feet'] = 0\n",
    "listings_less.loc[listings_less['square_feet']==0, 'is_nan_square_feet'] = 1 # add another column to indicate if nan square feet\n",
    "listings_less.loc[pd.isnull(listings_less['transit']), 'transit'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dummy variables for categorical variables\n",
    "listings_less_cat = listings_less.select_dtypes(include='object').copy()\n",
    "listings_less_cat.drop(['transit', 'amenities'], axis=1, inplace=True)\n",
    "listings_less_cat = pd.get_dummies(listings_less_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_less_num = listings_less.select_dtypes(include=['float64', 'int64']).copy()\n",
    "listings_less_num.drop(['price'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text features from transit \n",
    "# tutorial for text classification https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "X_text=listings_less['amenities']\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_text_counts = count_vect.fit_transform(X_text)\n",
    "X_text_names = count_vect.get_feature_names()\n",
    "print(X_text_counts.shape)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_text_tfidf = tfidf_transformer.fit_transform(X_text_counts)\n",
    "print(X_text_tfidf.shape)\n",
    "\n",
    "df_text = pd.DataFrame(data = X_text_tfidf.toarray(), columns = X_text_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([listings_less_cat, listings_less_num], axis=1)\n",
    "y = listings['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score # what is r2\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "print('Coefficient of determination: {0:.2f}'.format(r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df = pd.DataFrame({'feature_name': X_train.columns, 'coefs': regr.coef_, 'abs_coefs': np.abs(regr.coef_)}, \n",
    "                        columns=['feature_name', 'coefs', 'abs_coefs'])\n",
    "coefs_df.sort_values('abs_coefs', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
